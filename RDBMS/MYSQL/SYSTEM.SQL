---------------基于mysql5.7+---------------

-- 查看连接状态
show processlist;

-- 重新设置连接(不需要重连和权限认证),防止长连接过长,内存OOM导致mysql重启
mysql_reset_connection;

-- redo log是物理日志,只存在innodb引擎中,其他mysql引擎中不存在,binlog是逻辑日志,是mysql server层的实现,记录操作语句.
-- 设置redo log每一次事务都持久化到硬盘
innodb_flush_log_trx_commit = 1

-- 设置bin log每一次事务都持久化到硬盘
sync_binlog = 1

-- 事务隔离级别:
-- 读未提交(read uncommitted):
-- 读提交(read committed): 每个sql开始执行时创建视图(多个事务共享数据??)
-- 可重复读(repeatable read): 事务启动时创建试图,整个事务期间只使用这个试图(通过回滚日志实现??)
-- 串行化(serializable): 通过加锁方式实现,读写冲突时需要等待

-- 查看mysql隔离级别
show variables like 'transaction_isolation'

-- oracle默认隔离级别是'读提交',因此oracle迁移应用到mysql时,为了保证数据库隔离级别一致,需要设置MySQL启动参数
-- mysql默认是REPEATABLE-READ
transaction_isolation = READ_COMMITTED

-- 长事务,会保留这个事务中的任意数据,也即是老旧试图,会占用大量空间,同时占用锁资源,尽量避免长事务
-- 这个命令是关闭自动提交,当执行任意语句,默认就会开启一个事务(不需要显式begin),并且不自动提交,直到执行commit/rollback之前,这就是一个长事务
set autocommit = 0

-- 只有使用begin/start显式开启事务,然后使用commit提交,如果一个业务频繁使用事务,可以使用commit work and chain代替commit
-- 表示提交这个事务,并且启动下一个事务,省去主动执行begin/start的语句交互
set autocommit = 1

-- 查找超过60s的事务
SELECT * FROM information_schema.innodb_trx WHERE TIME_TO_SEC(TIMEDIFF(NOW(),trx_started)) > 60;


------------------------------------- 索引 -------------------------------------
-- 主键索引:聚簇索引(clustered index)叶子节点存的是整行数据,主键查询方式,只需要查询这一颗B+
-- 普通索引:二级索引(secondary index),叶子节点存的是主键值,查询时需要先查一次普通索引树,获取到主键值,然后进行回表操作,去主键树查询数据
-- B+树维护:当数据页数据满的时候(中间插入数据造成的数据页满载,递增造成满载不会发生也分裂),发生页分裂,影响性能,同时空间利用
-- 率降低(刚满的时候平分到两个数据页),当新增数据时,依次递增是最好的情况,索引树不需要挪动,只需要往后追加,这也是建议使用自增id
-- 作为主键的原因,避免插入的主键落入中间位置,后续的数据都要做出偏移,同时也不会触发页分裂;而业务逻辑字段不容保证有序插入,同时
-- 非主键索引的叶子都是主键值,那么主键值字节数越小,整体空间就越小,而自增id往往是int/bigint比string等其他业务字段节省空间.

-- 使用业务字段做主键的场景:只有一个索引,且是唯一索引,这个时候考虑主键索引

-- 索引优化:本质上都是减少回表操作
-- 1.覆盖索引:例如根据k查询主键id的时候,下面的语句,不需要回表操作,因为k索引树中的叶子节点上就是id主键值,减少回表,树的搜索次数
--          同时根据业务场景,利用联合索引实现覆盖索引,也可以减少回表操作.
SELECT * FROM t WHERE k BETWEEN 3 AND 5;
SELECT id FROM t WHERE k BETWEEN 3 AND 5;

-- 2.最左前缀:建立联合索引时候,第一原则是通过调整顺序实现最左原则,可以减少维护一个索引,当既有联合索引同时都涉及到各自的单独索引
--          这个时候空间原则有限,选择字段长度小的单独索引,大的作为联合索引:如 a>b 则联合索引(a,b),单独索引b

-- 3.索引下推:mysql5.6+引入了pushDown下推优化,当联合索引中的字段都在条件中时,会对第二个字段做出过滤,如:联合索引(author,age)
--          这个时候使用索引获取author是F开头的,然后进一步判断联合索引中的age字段做出过滤,5.6之前的版本不会对age字段做
--          过滤,会查出所有F开头的主键,然后逐个去主键B+中比对,而5.6之后会优先过滤出age字段,减少去主键B+的回表操作.
SELECT * FROM t WHERE author LIKE %F% AND age > 10;


------------------------------------- 锁 -------------------------------------
----------- 库级别锁:
-- 1.mysql提供了一种全局读锁(FLWRL),让整个数据库处于只读状态(不能有其他更新等操作),典型应用场景就是做全库的逻辑备份.
flush tables with read lock

-- 2.mysqldump使用参数single-transaction可以开启一致性事务,等同于可重复读的事务隔离级别,使用的是一致性视图,不影响
--   其他数据更新,但是要求是全库的所有表都要支持这个事务的隔离级别,比如MyISAM就不支持事务,因此不能使用.

--3.设置readonly参数可以让全库进入制度状态,但是缺点是当客户端出现异常是,数据库仍然保持readonly状态,而flwrl能自动释放全局锁
set global readonly = true

----------- 表级别锁:
-- 1.表锁,使用lock tables .. read/write语法实现,使用unlock tables解锁;如下,作用是限制其他线程写1,读写2,但是当前线程
--   也只能读1,读写2,不允许访问其他表,在没有出现行级锁之前,这种控制并发访问的粒度较大,影响面较广.
lock tables t1 read, t2 write

-- 2.另外一种是MDL(meta data lock)不需要显示使用,mysql5.5+引入,在访问一个表的时候会自动加上对应的读锁,写锁;避免当一个
--   线程读取数据时,另外一个线程修改了表结构,这样读取的数据就会与表结构不对应.读锁之间不互斥,读写锁以及写锁之间互斥,因此当执行
--   长事务的时候,另外的线程申请修改表结构等写锁会阻塞直到前一个事务执行完,这时第三个线程继续申请读锁,这个时候会阻塞直到写锁
--   完成释放,如果这个时候频繁请求读锁,会造成数据库线程爆满而挂掉.

-- 因此修改表结构要注意,长事务问题,查询innodb_trx表查看长事务kill掉,同时也根据数据库支持情况结合alisql的wait等语法尝试
-- 设置等待时间,一定时间内如果可以获取写锁就正常执行,否则就释放这个写锁,不阻碍后续的读锁,之后再不断尝试重复执行语句.
ALTER TABLE t NOWAIT ADD COLUMN ...;
ALTER TABLE t WAIT N ADD COLUMN ...;

----------- 行级别锁:
-- 1.innodb引擎支持行级别,MYISAM不支持;行锁是需要的时候才加上,但是不并不是执行完立刻释放,必须等事务结束才释放.
--   两阶段锁协议:行锁需要等待事务结束才释放,eg:一个事物中更新两行数据,第一行更新完不会释放第一个行锁,必须等等二行结束,同时
--   事务提交之后才释放这个两个行锁.因此当出现并发更新同一行的业务时,一定要将事务中其他不涉及并发的sql先执行,而涉及并发更新
--   同一行,就会竞争行锁,因此放到事务的最后执行,减少等待锁的时间.

-- 2.死锁,当出现循环依赖时发生死锁,eg:事务a执行更新id为1的语句时,事务b更新id为2的语句,紧接着事务a又申请更新id为2,事务b申请
--   更新id为1,这时事务a,b发生循环依赖发生死锁.
-- 2.1死锁超时策略:默认50s,等待超过50s第一个线程会超时退出,释放锁;但是这个超时时间过长,对于线上服务不可接受,同时又不能设置过
--   小,因为正常的不是死锁的业务可能被提前释放,造成误伤.
innodb_lock_wait_timeout = 50
-- 2.2死锁检测策略:默认开启,主动检测死锁当发现死锁的时候,回滚某一个线程事务;但是检测死锁的性能消耗较大,因为每发生一个事务被锁,
--   就要发起检测,假设1000个并发同时更新,那么死锁检测就是100w次,最终cpu爆炸.
indodb_deadlock_detect = on
-- 2.3因此死锁处理要具体看业务适当选择,如果确保业务没有死锁可以关掉死锁检测,同时可以考虑正常开启死锁检测,但是手动控制并发量,例如
--   通过中间件实现,也可以考虑将热点行数据分散到多行处理等